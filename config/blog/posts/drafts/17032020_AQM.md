---
title: Active Queue Management
draft: true
tags: networks
---



Since the beginning of Internet, engineers and scientists have been worried about network congestion. Some of these concerns caused the creation and implementation of several congestion control techniques that have survived until our days in the shape of TCP Congestion avoidance algorithms.

Most of these algorithms make use of dropped packets on a connection to sense congestion and act consequently. With the addition of buffers all across the network, the correct behavior of this type of congestion notification has been severely damaged. Such added buffers prevent packet losses, do not letting the transmitter to know about bottlenecks on the connection and adding unnecessary delay to the network path. This problem has been getting worse as time goes by.

Nowadays network has changed, delay is slowly replacing throughput as the key factor on a modern network and many providers have already changed their infrastructures to support more advanced queue management mechanisms like RED, PIE or CoDel.

Such that algorithms drop packets to warn the sender about congestion, replacing the legacy TCP congestion notification. How these new methods interfere with built-in congestion-avoidance algorithms included on TCP?

On this paper we are going to try to answer that question. For that purpose, we added several AQM algorithms to the TCP test suite created by the ICCRG[^1] and analyzed the interactions produced between these algorithms and different TCP flavors.

## TCP Congestion Avoidance Algorithms

This section is intended to act as a little review about the most important TCP congestion control variations that are in use nowadays. For that reason we have chosen some of the most representative TCP modifications such that CUBIC, which is the standard TCP extension used on Linux machines, Compound TCP which is implemented by default on Windows Operative Systems, LEDBAT which is one of the best representations of a TCP Congestion Control algorithm based on Low Priority Congestion Control and New Reno which is the basic scheme from all these other TCP modifications came from.

This concepts will be useful in order to analyze the interaction between TCP congestion avoidance algorithms and the different queue managers deployed in this experiment.


### TCP NewReno

TCP NewReno[^2] is an evolution of the original TCP Reno which aims to keep window transmission full when it is in recovery mode by adding Fast Retransmission algorithm together with the other three native congestion control algorithms implemented on TCP Reno: Slow Start, Congestion Avoidance and Fast Recovery

First of all, let us talk about Slow Start and Congestion Avoidance. These two algorithms try to control the amount of data sent to the link so as to achieve the maximum available throughput. In order to do that, two parameters are used: The first one is the window size ,$win$, which controls the number of packets that can be sent in a row and the second one is $ssthresh$ which indicates the number of packets that can be sent until the connection enters into congestion-avoidance mode. Window size is usually initialized to three times the Maximum Segment Size while $sstresh$ is 64 Kb by default.

While $win$ is less than $sstresh$, for every ACK received, the sender increases the window by one packet. That is the so called Slow Start algorithm which it is not so slow, in fact, it leads to an exponential window increase that aims to achieve the maximum possible bandwidth in the minimum possible time.

When $sstresh$ value has been reached, connection goes into congestion-avoidance mode and it starts to increase the window linearly, by adding $\frac{1}{win}$ to the actual window value. If some packet is lost, the sender resets the window to its initial value and recompute the threshold to half the value of the current window at that moment.

If some packet is missed, the receiver keeps sending the acknowledgment packet that corresponds to the last packet received before the packet loss until the missing packet is received. As a result of this, the sender will receive more than one ACK with the same sequence number. If it receives three duplicated ACK's, it infers that this particular packet has been lost and sends it again without waiting for the retransmission timer to expire. This behavior is called Fast Retransmit.

When that happens, instead of applying the congestion-avoidance rule and set the window to one, the sender sets the window to $sstresh + 3 $, skipping the Slow start phase and going directly to the congestion avoidance phase (because the new threshold is $\frac{win}{2}$ thus the actual window is bigger). This is called Fast Recovery.

\begin{lstlisting}
 win = 3
 sstresh = 64Kb
 if(win<sstresh) win = win + 1
 if(win>sstresh) win = win + (1/win)
 if(packet_loss) {
	sstresh = win/2;
	win = 1
if(duplicated_ack){
	stresh = win/2
   win= stresh + 3
}   
\end{lstlisting}

\begin{figure}[h!]
\includegraphics[width=7cm]{graphs/newReno}
\centering
\caption{New Reno}
\end{figure}


### Cubic

Cubic \cite{cubic} is the current default TCP algorithm implemented on Linux machines. It is an improved version of BIC-TCP that tries to simplify the window control and enhance it's friendliness with standard TCP. This protocol replace the linear window growth function with a cubic function in order to increase link utilization on networks with very large bandwidth per delay product (BDP).

When an acknowledgment is received, the window is updated according to the following formula:

\[ w(t) = C(t-K)^3+ w_{max}\]

where $C$ is a scaling factor, $t$ is the elapsed time since the last window reduction, $w_{max}$ is the window size just before the last window reduction and $K$ is a factor that is updated at the time of the last congestion event by using the following formula:

\[ K = \sqrt[3]{ \frac{w_{max}\cdot \beta} {C} }  \]

Where $\beta$ is a constant multiplication decrease factor, which also helps to update the size of $ w_{max}$ together with $K$ when there is a packet loss with:

\[  w_{max}(t) = \beta \cdot  w_{max}(t-1) \]

As we can observe, Cubic has two phases. The first concave one, where the window rapidly increases towards the size it had just before the last congestion event and the second one when the size of the window has surpassed the value of $w_{max}$ and the increase is convex, trying to probe the network in order to achieve the best bandwidth without damaging stability.

\begin{figure}[h!]
\includegraphics[width=7cm]{graphs/CUBIC}
\centering
\caption{CUBIC window progression}
\end{figure}


### Compound TCP

Compound TCP \cite{ctcp} is an algorithm developed by Microsoft that was introduced on 2008 as part of Windows Vista. It basically adds a delay-based component to TCP New Reno with the purpose of improving link utilization on high speed low distance networks.

This addition creates an hybrid between a pure delay-based congestion control (based on HS-TCP) and a classic loss-based congestion control. The included delay-based component helps to increase aggressively the window when the network is under-utilized and reduce the sending rate when it senses that the link is fully utilized, that is, in the presence of queuing delay.

CTCP maintains two independent windows: the loss-based window $cwnd$ and the delay based window $dwnd$. If the algorithm is in congestion-avoidance phase, the actual window is the minimum between the sum of these two windows and the advertised window of the receiver. The loss-delay congestion algorithms remain untouched and are equal to New Reno. The delay component use a variable $RTT_{base}$ as transmission delay estimator. With this measure we can figure out the throughput we expect to receive 
\[
thr_{expct} = win / RTT_{base}
\]
and if we compare this estimator with the actual throughput 
\[
thr_{now} = win/RTT
\]
we can then infere the number of packets that are stuck on the bottleneck
\[
diff = (thr_{expct}-thr_{now})\cdot RTT_{base}
\]
If this value is bigger than a predefined target value ($\gamma$), then it assumes that there is congestion on the link.

Until know, we just saw how the delay-based component of the CTCP protocol detects congestion. The increase law that control the congestion window is the following:

\begin{equation}\label{CTCPEQ}
dwnd(t+1) = \left\{\begin{matrix}
dwnd(t)+ \alpha \cdot win(t)^k - 1 & diff < \gamma \\ 
dwnd(t) - \zeta \cdot diff & diff \geq \gamma \\
win(t) \cdot (1-\beta) - \frac{cwnd}{2} & packet\:losses 
\end{matrix}\right.
\end{equation}

We have to take into account that the delay-based component acts as a complement of the New Reno algorithm. For instance, in the increase phase, when target $\gamma$ is bigger than $diff$, increment of $dwnd$ will be conditioned by the loss-based component which will increase by one packet. When there is a loss, it also does the same regarding the reduction provided by $cwnd$. In such that situation, $\zeta$ is a very important coefficient which controls the speed on the reduction of $dwnd$ when there is congestion.

\begin{figure}[h!]
\includegraphics[width=7cm]{graphs/CTCP}
\centering
\caption{CTCP window progression}
\end{figure}

### LEDBAT

Low Extra Delay Background Transport (LEDBAT) \cite{RFC6817} is a delay-based congestion control algorithm designed to use just the spared bandwidth on and end-to-end link while trying to keep the queuing delay as low as possible.

In order to achieve this, it measures the one-way delay and reduces its rate when delay increases. This behaviour make LEDBAT less aggressive than Standard TCP, reacting fast to congestion events and not inducing extra queuing delay in the network.

LEDBAT is configured by using two parameters: 
\begin{itemize}
    \item The maximum queuing delay that it can induce to the network ($q_{target}$) which is 25 ms by default.
    \item The gain, defined as the rate at which the congestion window $cwnd$ responds to the changes in queueing delay (1 by default).
\end{itemize}

Besides these two parameters, LEDBAT computes another values when an acknowledgment is received in order to set the congestion window: base delay, queuing delay and target offset. Base delay is the minimum between the current delay (measured via the last acknowledged packet) and the last computed base delay. Queuing delay is the difference between base delay and current delay. This value is necessary to calculate target offset which represents the normalized value between the measured queuing delay and the specified target delay:

\[
off_{target} = \frac{d_{target}-d_{queue}}{d_{target}} \\
\]

The actual window size is then computed as follows:

\[
cwnd \leftarrow cwnd + \frac{Gain \cdot off_{target} \cdot bytes_{acked} \cdot MSS}{cwnd}
\]

If a packet loss is detected, actual congestion window is reduced by half its value, just like TCP. So in the worst scenario, LEDBAT would act as a standard TCP.

It is very interesting to test this algorithm together with different AQM mechanisms because low priority congestion control (LPCC) strategies such that the methods deployed on LEDBAT has been one of the alternatives to AQM proposed by the research community in order to reduce bufferbloat.

Besides that, LEDBAT has been widely deployed. Apple use this protocol to distribute software updates and uTorrent added it to its uTP protocol.

### Initial congestion window to 10

Some of the previously commented TCP flavors have been tested  with a modification proposed \cite{I-D.ietf-tcpm-initcwnd} which increases the initial TCP window from 3 to 10 MSS. It has been proven \cite{36640} that this modification could have a moderate benefit for short lived connections although it is obvious than a larger initial window increases the burstiness of the traffic and this could affect significantly to the average queuing delay.

Some other reports \cite{I-D.gettys-iw10-considered-harmful} indicates that the impact of this modification on the latency is huge enough to advice not to make such that modification. Nevertheless, this report is targeted to a very specific service (web browsing) which has its own idiosyncrasies and its conclusions are based on a old protocol version (http1.1). Besides that, this draft talks about queues presumably without any advance queue management policy. We will try to figure out if these type of managers could mitigate the latency problem and, at the same time, improve overall throughput when using this increased initial window.  





## Bibliography

[^1]: [Common TCP evaluation suite](http://www.ietf.org/internet-drafts/draft-irtf-tmrg-tests-02.txt)
[^2]: [RFC6582]()